{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AIM 460 – Group Project #3: Neural Networks vs. Classical Methods\n",
        "\n",
        "> **Notebook setup**  \n",
        "> - Title: “Project 3: Deep & Wide Nets, RNNs, Kernels & Regressions”  \n",
        "> - At top, include a “How to run this notebook” section with Colab runtime specs, required libraries (PyTorch, scikit-learn, pandas, etc.) and fixed random seeds.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Data Gathering & Description  \n",
        "1. Collect **two** original datasets (≥ 3 000 examples each, ≥ 5 features) with at least one via an API.  \n",
        "2. Upload data to github, embed your scripts or links, show sample raw output, and write 2–3 sentences about any engineering challenges.  \n",
        "3. Do a complete cleaning, preprocessing, and EDA, including any imputation. This must be accompanied by clear commentary and explanation. Make sure to justify your approach and explain any missing or corrupt values you observe.\n",
        "4. Detect outliers (e.g. via IQR) and treat or justify retaining them.  \n",
        "3. Encode categorical fields (one-hot or ordinal) and scale numeric features, noting in a markdown cell the rationale behind each transformation.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Feature Engineering  \n",
        "1. Create **at least three** new, domain-driven features (e.g. rolling averages, ratios, interaction terms).  \n",
        "2. For each feature, include a short markdown explanation of what it captures and why it should help your models.\n",
        "3. Do any other feature engineering techniques that would be helpful.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Baseline Regression & Kernel Methods  \n",
        "1. Train ordinary least squares and ridge regressors (use scikit-learn).  \n",
        "2. Train kernel ridge regression with **RBF** and **polynomial** kernels, tuning `alpha`, `gamma`, `degree` via manual grid search.  \n",
        "3. Log training time and validation MSE for every hyperparameter setting and plot errors vs. parameter values.\n",
        "4. Do the same for LASSO and Elastic net.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Feedforward Neural Networks in PyTorch  \n",
        "1. Define three `nn.Module` architectures:  \n",
        "   - **Shallow** (1 hidden layer)  \n",
        "   - **Deep** (≥ 4 hidden layers)  \n",
        "   - **Wide** (single layer with large width)  \n",
        "2. For each, run two experiments:  \n",
        "   - **Baseline**: no batch norm, no dropout  \n",
        "   - **Enhanced**: add batch normalization, dropout, and replace ReLU with one custom activation (e.g. Swish or Mish)  \n",
        "3. For both runs, plot training & validation loss curves, record final MSE (or classification metrics).\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Recurrent Neural Network Extension  \n",
        "1. Reframe one dataset as sequences (e.g. time-series windows) and build a simple LSTM or GRU regressor/classifier.  \n",
        "2. Train and evaluate it, then compare its performance—both accuracy/MSE and convergence speed—against your MLPs and kernel regressors.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Feature-Transfer Experiment  \n",
        "1. Freeze the penultimate layer of your best-performing feedforward network.  \n",
        "2. Extract its learned representations on your datasets.  \n",
        "3. Train a linear or kernel regressor/classifier on these features and compare results against your direct regressions.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Results, Reflection & Submission  \n",
        "1. In markdown cells, after each major section, answer these two prompts in 2–3 sentences each:  \n",
        "   - “What was the single hardest bug or training issue you faced here (include error messages or plots)?”  \n",
        "   - “What new insight did you gain about model behavior that no black-box solution could teach you?”  \n",
        "2. Display final performance tables and error-distribution histograms or confusion matrices.  \n",
        "3. Submit **one** Colab/Jupyter notebook and **one** slide deck to GitHub per group. Include all data-collection scripts, notebooks, slides, and ensure every group member’s name appears.  \n"
      ],
      "metadata": {
        "id": "Xsj4mcLEE2oq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERlmJZu1E1V1"
      },
      "outputs": [],
      "source": []
    }
  ]
}