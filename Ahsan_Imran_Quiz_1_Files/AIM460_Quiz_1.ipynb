{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e881260-ebad-4009-b7fe-7b1f94f5ad88",
   "metadata": {},
   "source": [
    "# Comprehensive k-Nearest Neighbors Assignment - Quiz 1\n",
    "## Real Estate Price Prediction with Advanced k-NN Implementation\n",
    "\n",
    "**Due Date:** Aug 31 11:59pm  \n",
    "**Points:** 100  \n",
    "**Individual Assignment - Academic Integrity Required**\n",
    "\n",
    "---\n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "You will build a complete machine learning pipeline using k-Nearest Neighbors to predict house prices using the a housing dataset of your choice. This assignment requires you to demonstrate deep understanding of k-NN concepts, data preprocessing, feature engineering, and model evaluation while implementing several components from scratch to prove your understanding.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "One choice is the California Housing Dataset, as seen below, although you may choose a different dataset. You must create a folder in Github containing your data as well as your ipynb notebook. \n",
    "\n",
    "**Dataset:** California Housing Dataset (sklearn.datasets.fetch_california_housing)\n",
    "- **Samples:** 20,640 house observations\n",
    "- **Features:** 8 numerical features\n",
    "- **Target:** Median house value (in hundreds of thousands of dollars)\n",
    "\n",
    "**Features:**\n",
    "- `MedInc`: Median income in block group\n",
    "- `HouseAge`: Median house age in block group  \n",
    "- `AveRooms`: Average number of rooms per household\n",
    "- `AveBedrms`: Average number of bedrooms per household\n",
    "- `Population`: Block group population\n",
    "- `AveOccup`: Average number of household members\n",
    "- `Latitude`: Block group latitude\n",
    "- `Longitude`: Block group longitude\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Data Loading and Exploration \n",
    "\n",
    "### 1.1 Data Loading and Initial Inspection \n",
    "```python\n",
    "# Load the dataset and create initial DataFrame\n",
    "# Display basic information about the dataset\n",
    "# Show first/last few rows\n",
    "# Check data types and basic statistics\n",
    "```\n",
    "\n",
    "**Requirements:**\n",
    "- Load the dataset using sklearn\n",
    "- Create a pandas DataFrame with proper column names\n",
    "- Display dataset shape, info(), and describe()\n",
    "- Identify the target variable and feature types\n",
    "\n",
    "### 1.2 Comprehensive EDA \n",
    "\n",
    "Create visualizations and analysis for:\n",
    "\n",
    "**A. Target Variable Analysis:**\n",
    "- Distribution of house prices (histogram, box plot)\n",
    "- Summary statistics with interpretation\n",
    "- Identify potential outliers in target variable\n",
    "\n",
    "**B. Feature Analysis:**\n",
    "- Individual feature distributions (histograms for all features)\n",
    "- Identify skewed distributions and potential transformations needed\n",
    "- Correlation matrix heatmap\n",
    "- Scatter plots of each feature vs target\n",
    "\n",
    "**C. Geographic Analysis:**\n",
    "- Scatter plot of Latitude vs Longitude colored by house price\n",
    "- Identify geographic patterns in housing prices\n",
    "- Discussion of California geography impact on prices\n",
    "\n",
    "**D. Feature Relationships:**\n",
    "- Identify the top 3 strongest correlations with target\n",
    "- Create scatter plots with trend lines for these relationships\n",
    "- Analyze multicollinearity between features\n",
    "\n",
    "**Written Requirement:** Provide 2-3 paragraph analysis of your EDA findings, including insights about the housing market and potential challenges for modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Data Cleaning and Preprocessing \n",
    "\n",
    "### 2.1 Missing Value Analysis \n",
    "- Check for missing values in all columns\n",
    "- If missing values exist, analyze patterns and implement appropriate handling\n",
    "- Document your decision-making process\n",
    "\n",
    "### 2.2 Outlier Detection and Handling \n",
    "\n",
    "**Implement and apply TWO methods:**\n",
    "\n",
    "**Method 1: Statistical Outlier Detection**\n",
    "```python\n",
    "def detect_outliers_iqr(data, column, factor=1.5):\n",
    "    \"\"\"\n",
    "    Detect outliers using IQR method\n",
    "    \n",
    "    Parameters:\n",
    "    data: DataFrame\n",
    "    column: column name to check\n",
    "    factor: IQR multiplier (default 1.5)\n",
    "    \n",
    "    Returns:\n",
    "    Boolean series indicating outliers\n",
    "    \"\"\"\n",
    "    # YOUR IMPLEMENTATION HERE\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Method 2: Z-Score Outlier Detection**\n",
    "```python\n",
    "def detect_outliers_zscore(data, column, threshold=3):\n",
    "    \"\"\"\n",
    "    Detect outliers using Z-score method\n",
    "    \n",
    "    Parameters:\n",
    "    data: DataFrame  \n",
    "    column: column name to check\n",
    "    threshold: Z-score threshold (default 3)\n",
    "    \n",
    "    Returns:\n",
    "    Boolean series indicating outliers\n",
    "    \"\"\"\n",
    "    # YOUR IMPLEMENTATION HERE\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Requirements:**\n",
    "- Apply both methods to all numerical features\n",
    "- Create visualizations showing outliers before and after removal\n",
    "- Compare the two methods and justify which approach you choose\n",
    "- Document impact on dataset size\n",
    "\n",
    "### 2.3 Feature Engineering \n",
    "\n",
    "**Create the following engineered features:**\n",
    "\n",
    "1. **Ratio Features:**\n",
    "   - `rooms_per_household`: AveRooms / AveOccup\n",
    "   - `bedrooms_per_room`: AveBedrms / AveRooms\n",
    "   - `population_per_household`: Population / AveOccup\n",
    "\n",
    "2. **Geographic Features:**\n",
    "   - `distance_to_LA`: Distance from Los Angeles (34.0522°N, 118.2437°W)\n",
    "   - `distance_to_SF`: Distance from San Francisco (37.7749°N, 122.4194°W)\n",
    "   - `coastal_proximity`: Binary feature (1 if longitude > -121, 0 otherwise)\n",
    "\n",
    "3. **Categorical Features:**\n",
    "   - `income_category`: Low (<3), Medium (3-6), High (6-9), Very High (9+)\n",
    "   - `house_age_category`: New (<10), Medium (10-30), Old (30+)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Part 3: Custom k-NN Implementation \n",
    "\n",
    "### 3.1 Distance Metrics Implementation \n",
    "\n",
    "**Implement these distance functions from scratch:**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate Euclidean distance between two points\n",
    "    \n",
    "    Parameters:\n",
    "    point1, point2: numpy arrays of equal length\n",
    "    \n",
    "    Returns:\n",
    "    float: Euclidean distance\n",
    "    \"\"\"\n",
    "    # YOUR IMPLEMENTATION HERE\n",
    "    pass\n",
    "\n",
    "def manhattan_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate Manhattan distance between two points\n",
    "    \n",
    "    Parameters:\n",
    "    point1, point2: numpy arrays of equal length\n",
    "    \n",
    "    Returns:\n",
    "    float: Manhattan distance  \n",
    "    \"\"\"\n",
    "    # YOUR IMPLEMENTATION HERE\n",
    "    pass\n",
    "\n",
    "def minkowski_distance(point1, point2, p=2):\n",
    "    \"\"\"\n",
    "    Calculate Minkowski distance between two points\n",
    "    \n",
    "    Parameters:\n",
    "    point1, point2: numpy arrays of equal length\n",
    "    p: parameter (p=1 gives Manhattan, p=2 gives Euclidean)\n",
    "    \n",
    "    Returns:\n",
    "    float: Minkowski distance\n",
    "    \"\"\"\n",
    "    # YOUR IMPLEMENTATION HERE\n",
    "    pass\n",
    "```\n",
    "\n",
    "### 3.2 k-NN Class Implementation \n",
    "\n",
    "**Implement a complete k-NN class:**\n",
    "\n",
    "```python\n",
    "class CustomKNN:\n",
    "    def __init__(self, k=5, distance_metric='euclidean', weights='uniform'):\n",
    "        \"\"\"\n",
    "        Custom k-NN implementation\n",
    "        \n",
    "        Parameters:\n",
    "        k: number of neighbors\n",
    "        distance_metric: 'euclidean', 'manhattan', or 'minkowski'\n",
    "        weights: 'uniform' or 'distance'\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weights = weights\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Store training data\"\"\"\n",
    "        # YOUR IMPLEMENTATION HERE\n",
    "        pass\n",
    "    \n",
    "    def _calculate_distance(self, point1, point2):\n",
    "        \"\"\"Calculate distance based on selected metric\"\"\"\n",
    "        # YOUR IMPLEMENTATION HERE\n",
    "        pass\n",
    "    \n",
    "    def _get_neighbors(self, test_point):\n",
    "        \"\"\"Find k nearest neighbors for a test point\"\"\"\n",
    "        # YOUR IMPLEMENTATION HERE\n",
    "        # Return indices of k nearest neighbors\n",
    "        pass\n",
    "    \n",
    "    def predict_single(self, test_point):\n",
    "        \"\"\"Predict for a single test point\"\"\"\n",
    "        # YOUR IMPLEMENTATION HERE\n",
    "        # Handle both uniform and distance-weighted predictions\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict for multiple test points\"\"\"\n",
    "        # YOUR IMPLEMENTATION HERE\n",
    "        pass\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"Calculate R-squared score\"\"\"\n",
    "        # YOUR IMPLEMENTATION HERE\n",
    "        pass\n",
    "```\n",
    "\n",
    "**Requirements:**\n",
    "- Implement all methods completely\n",
    "- Handle both uniform and distance-weighted predictions\n",
    "- Include proper error handling\n",
    "- Add docstrings for all methods\n",
    "\n",
    "---\n",
    "\n",
    "## Part 4: Manual Calculations (Proof of Understanding) \n",
    "\n",
    "### 4.1 Distance Calculations \n",
    "\n",
    "**Select 3 specific data points from your dataset and manually calculate (by hand, with a picture to be uploaded to Github in the same folder):**\n",
    "\n",
    "1. Euclidean distance between points 1 and 2\n",
    "2. Manhattan distance between points 1 and 3  \n",
    "3. Minkowski distance (p=3) between points 2 and 3\n",
    "\n",
    "**Show all work step by step. Include:**\n",
    "- The actual feature values used\n",
    "- Complete mathematical formulation\n",
    "- Step-by-step calculation\n",
    "- Verification using your implemented functions\n",
    "\n",
    "### 4.2 k-NN Prediction Walkthrough \n",
    "\n",
    "**For a specific test instance:**\n",
    "\n",
    "1. **Manual Neighbor Finding:**\n",
    "   - Select a test point from your test set\n",
    "   - Calculate distances to ALL training points (show first 10 calculations)\n",
    "   - Identify the 5 nearest neighbors manually\n",
    "   - Show the ranking process\n",
    "\n",
    "2. **Prediction Calculation:**\n",
    "   - Calculate uniform weighted prediction\n",
    "   - Calculate distance-weighted prediction  \n",
    "   - Show all mathematical steps\n",
    "   - Compare with your implementation results\n",
    "\n",
    "**Format Example:**\n",
    "```\n",
    "Test Point: [6.2, 15.0, 5.5, 1.1, 3000, 3.2, 33.8, -118.1]\n",
    "\n",
    "Distance Calculations:\n",
    "Point 1: [5.8, 20.0, 4.2, ...]  → Distance = √[(6.2-5.8)² + (15.0-20.0)² + ...] = X.XX\n",
    "Point 2: [7.1, 10.0, 6.1, ...]  → Distance = √[(6.2-7.1)² + (15.0-10.0)² + ...] = X.XX\n",
    "...\n",
    "\n",
    "5 Nearest Neighbors:\n",
    "1. Point Index: 1234, Distance: 2.45, Target: 3.2\n",
    "2. Point Index: 5678, Distance: 2.67, Target: 2.9\n",
    "...\n",
    "\n",
    "Uniform Prediction: (3.2 + 2.9 + ...) / 5 = X.XX\n",
    "Distance Weighted: [Show complete calculation]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Part 5: Model Evaluation and Hyperparameter Tuning \n",
    "\n",
    "### 5.1 Train-Test Split and Scaling \n",
    "\n",
    "```python\n",
    "# Split data (80/20 split)\n",
    "# Apply appropriate scaling (compare StandardScaler vs MinMaxScaler)\n",
    "# Justify your scaling choice based on EDA findings\n",
    "```\n",
    "\n",
    "### 5.2 Hyperparameter Grid Search \n",
    "\n",
    "**Implement a manual grid search:**\n",
    "\n",
    "```python\n",
    "def manual_grid_search(X_train, y_train, X_val, y_val, param_grid):\n",
    "    \"\"\"\n",
    "    Perform manual grid search for k-NN hyperparameters\n",
    "    \n",
    "    Parameters:\n",
    "    X_train, y_train: Training data\n",
    "    X_val, y_val: Validation data  \n",
    "    param_grid: Dictionary of parameters to search\n",
    "    \n",
    "    Returns:\n",
    "    best_params: Best parameter combination\n",
    "    results_df: DataFrame with all results\n",
    "    \"\"\"\n",
    "    # YOUR IMPLEMENTATION HERE\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Search Grid:**\n",
    "- k: [3, 5, 7, 9, 11, 15, 21]\n",
    "- distance_metric: ['euclidean', 'manhattan']  \n",
    "- weights: ['uniform', 'distance']\n",
    "\n",
    "**Requirements:**\n",
    "- Use 5-fold cross-validation\n",
    "- Track both training and validation scores\n",
    "- Create visualization of results\n",
    "- Identify best parameters and analyze patterns\n",
    "\n",
    "### 5.3 Performance Analysis\n",
    "\n",
    "**Create comprehensive evaluation:**\n",
    "\n",
    "1. **Learning Curves:** Plot training and validation scores vs k\n",
    "2. **Distance Metric Comparison:** Visualize performance differences\n",
    "3. **Feature Importance Analysis:** Which features contribute most to neighbor selection?\n",
    "4. **Error Analysis:** Analyze residuals and identify prediction patterns\n",
    "\n",
    "---\n",
    "\n",
    "## Part 6: Comparison and Advanced Analysis\n",
    "\n",
    "### 6.1 Sklearn Comparison\n",
    "- Compare your implementation with sklearn's KNeighborsRegressor\n",
    "- Verify results match (within reasonable tolerance)\n",
    "- Analyze any performance differences\n",
    "\n",
    "### 6.2 Curse of Dimensionality Analysis\n",
    "- Create a synthetic high-dimensional dataset of random data\n",
    "- Show how k-NN performance degrades with increasing dimensions\n",
    "- Discuss implications for feature selection\n",
    "\n",
    "---\n",
    "\n",
    "## Deliverables and Submission Requirements\n",
    "\n",
    "### Required Files:\n",
    "1. **Jupyter Notebook:** `lastname_firstname_knn_assignment.ipynb`\n",
    "2. **PDF Report:** `lastname_firstname_knn_report.pdf` (exported from notebook)\n",
    "\n",
    "### Academic Integrity Requirements:\n",
    "\n",
    "**To prove you completed this work yourself, include:**\n",
    "\n",
    "1. **Process Documentation:**\n",
    "   - Comments explaining your thought process for each major decision throughout the notebook.\n",
    "   - Personal insights and analysis throughout\n",
    "\n",
    "2. **Understanding Verification:**\n",
    "   - All manual calculations must be shown step-by-step\n",
    "   - Explain why you chose specific parameter values\n",
    "   - Discuss what you learned from each analysis\n",
    "\n",
    "3. **Code Comments:**\n",
    "   - Every function must have detailed comments\n",
    "   - Complex logic must be commented line-by-line\n",
    "   - Include reasoning for implementation choices\n",
    "\n",
    "4. **Personal Analysis:**\n",
    "   - Write conclusions in your own words\n",
    "   - Discuss surprises or unexpected findings\n",
    "   - Explain how this assignment changed your understanding of k-NN\n",
    "\n",
    "### Further Measures:\n",
    "\n",
    "**Include these specific elements to demonstrate understanding:**\n",
    "\n",
    "1. **Conceptual Questions (Answer in your Colab or Jupyter notebook):**\n",
    "   - Why might Manhattan distance be preferable to Euclidean distance in certain scenarios?\n",
    "   - How does the choice of k affect bias-variance tradeoff in k-NN?\n",
    "   - What are the computational implications of different distance metrics?\n",
    "   - How would you modify k-NN for categorical features?\n",
    "\n",
    "2. **Implementation Decisions:**\n",
    "   - Discuss alternative approaches you considered\n",
    "   - Identify limitations of your implementation\n",
    "\n",
    "3. **Personal Reflection:**\n",
    "   - What was the most challenging part of this assignment?\n",
    "   - How would you improve your approach if you had more time?\n",
    "   - What real-world applications could benefit from your analysis?\n",
    "\n",
    "---\n",
    "\n",
    "## Grading Rubric\n",
    "\n",
    "| Component | Criteria |\n",
    "|-----------|----------|\n",
    "| **Data Exploration** | Complete EDA with insights, proper visualizations, written analysis |\n",
    "| **Data Preprocessing** | Correct outlier handling, feature engineering, documentation |\n",
    "| **Custom Implementation** | Working k-NN class, multiple distance metrics, proper structure |\n",
    "| **Manual Calculations** | Step-by-step work shown, correct calculations, verification |\n",
    "| **Model Evaluation** | Comprehensive analysis, proper validation, hyperparameter tuning |\n",
    "| **Advanced Analysis** | Sklearn comparison, dimensionality analysis |\n",
    "| **Code Quality**  | Clean code, comments, documentation, organization |\n",
    "| **Academic Integrity** | Evidence of original work, personal insights, understanding demonstration |\n",
    "| **Presentation** | Clear notebook organization, professional formatting |\n",
    "\n",
    "**Total: 100 points** \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Academic Integrity Statement\n",
    "\n",
    "By submitting this assignment, I certify that:\n",
    "- All code was written by me (our group) personally\n",
    "- All analysis and insights are mine (or our groups) original work  \n",
    "- I understand the concepts demonstrated in my implementation\n",
    "- I have properly cited any external resources used\n",
    "- I am prepared to explain any part of my solution in detail\n",
    "\n",
    "**Student Signature:** ___Ahsan Imran_______ **Date:** ___8/31/2025___\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
